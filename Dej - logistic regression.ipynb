{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "\n",
    "# Machine learning packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_excel(r'cleaned data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train has 875 rows \n",
      "y_train has 875 rows \n",
      "X_val has 219 rows \n",
      "y_val has 219\n"
     ]
    }
   ],
   "source": [
    "X = data_df.drop(columns=['Take-up ind', 'Pno'])\n",
    "y = data_df['Take-up ind']\n",
    "\n",
    "# Split the dataset using the train_test_split function\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, random_state=7, stratify=y)\n",
    "\n",
    "# split into train and test\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, random_state=7, stratify=y)\n",
    "\n",
    "print('X_train has %d rows \\ny_train has %d rows \\nX_val has %d rows \\ny_val has %d' \n",
    "      %(X_train.shape[0], y_train.shape[0], X_val.shape[0],y_val.shape[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\E1005280\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=7, max_iter=2000)\n",
    "\n",
    "# Fit and save the logistic regression model using the training data\n",
    "model = logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing Data Score:\t0.9097142857142857\n",
      "Testing Data Score:\t0.9269406392694064\n"
     ]
    }
   ],
   "source": [
    "# Validate the model\n",
    "train_pred = model.predict(X_train)\n",
    "train_score = accuracy_score(y_train, train_pred)\n",
    "\n",
    "test_pred = model.predict(X_val)\n",
    "test_score = accuracy_score(y_val, test_pred)\n",
    "\n",
    "print(f'Traing Data Score:\\t{train_score}')\n",
    "print(f'Testing Data Score:\\t{test_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>198</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0          198           16\n",
       "Actual 1            0            5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "cm = confusion_matrix(y_val_pred, y_val)\n",
    "cm_df = pd.DataFrame(cm, index=['Actual 0', 'Actual 1'], columns=['Predicted 0', 'Predicted 1'])\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, y_prob=None, metrics=['precision', 'recall', 'f1', 'accuracy', 'auc']):\n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    TP = cm[1, 1]\n",
    "    FP = cm[0, 1]\n",
    "    TN = cm[0, 0]\n",
    "    FN = cm[1, 0]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # Calculate precision\n",
    "    if 'precision' in metrics:\n",
    "        results['precision'] = round( TP / (TP + FP), 4) if (TP + FP) > 0 else 0\n",
    "\n",
    "    # Calculate recall\n",
    "    if 'recall' in metrics:\n",
    "        results['recall'] = round( TP / (TP + FN), 4) if (TP + FN) > 0 else 0\n",
    "\n",
    "    # Calculate F1 score\n",
    "    if 'f1' in metrics:\n",
    "        results['f1'] = round( 2 * (TP / (2 * TP + FP + FN)), 4) if (2 * TP + FP + FN) > 0 else 0\n",
    "\n",
    "    # Calculate accuracy\n",
    "    if 'accuracy' in metrics:\n",
    "        results['accuracy'] = round( (TP + TN) / (TP + TN + FP + FN), 4)\n",
    "\n",
    "    # Calculate AUC\n",
    "    if 'auc' in metrics and y_prob is not None:\n",
    "        # Note: AUC requires probabilities, not class labels.\n",
    "        results['auc'] = round( roc_auc_score(y_true, y_prob), 4)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 1.0, 'recall': 0.2381, 'f1': 0.3846, 'accuracy': 0.9269, 'auc': 0.619}\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "metrics = calculate_metrics(y_true=y_val, y_pred=y_val_pred, y_prob=y_val_pred,\n",
    "                            metrics=['precision', 'recall', 'f1', 'accuracy', 'auc'])\n",
    "print(metrics)\n",
    "# {'precision': 1.0, 'recall': 0.2105, 'f1': 0.3478, 'accuracy': 0.9315}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.6667, 'recall': 0.0964, 'f1': 0.1684, 'accuracy': 0.9097, 'auc': 0.5457}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>788</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0          788           75\n",
       "Actual 1            4            8"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "# Metrics\n",
    "metrics = calculate_metrics(y_true=y_train, y_pred=y_train_pred, y_prob=y_train_pred, \n",
    "                            metrics=['precision', 'recall', 'f1', 'accuracy', 'auc'])\n",
    "print(metrics)\n",
    "cm = confusion_matrix(y_train_pred, y_train)\n",
    "cm_df = pd.DataFrame(cm, index=['Actual 0', 'Actual 1'], columns=['Predicted 0', 'Predicted 1'])\n",
    "\n",
    "cm_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
