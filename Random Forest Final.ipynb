{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import model_to_dot, plot_model\n",
    "from keras_tuner import HyperModel, RandomSearch, Objective\n",
    "\n",
    "## \"Normal\" libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (auc, precision_recall_curve, confusion_matrix,\n",
    "                             roc_auc_score, roc_curve, classification_report,\n",
    "                             precision_score, recall_score, f1_score, accuracy_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_value_counts(array):\n",
    "    array = np.array(array)  # Convert to numpy array if not already\n",
    "    unique, counts = np.unique(array, return_counts=True)\n",
    "    return dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, y_prob=None, metrics=['precision', 'recall', 'f1', 'accuracy', 'auc']):\n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    TP = cm[1, 1]\n",
    "    FP = cm[0, 1]\n",
    "    TN = cm[0, 0]\n",
    "    FN = cm[1, 0]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # Calculate precision\n",
    "    if 'precision' in metrics:\n",
    "        results['precision'] = round( TP / (TP + FP), 4) if (TP + FP) > 0 else 0\n",
    "\n",
    "    # Calculate recall\n",
    "    if 'recall' in metrics:\n",
    "        results['recall'] = round( TP / (TP + FN), 4) if (TP + FN) > 0 else 0\n",
    "\n",
    "    # Calculate F1 score\n",
    "    if 'f1' in metrics:\n",
    "        results['f1'] = round( 2 * (TP / (2 * TP + FP + FN)), 4) if (2 * TP + FP + FN) > 0 else 0\n",
    "\n",
    "    # Calculate accuracy\n",
    "    if 'accuracy' in metrics:\n",
    "        results['accuracy'] = round( (TP + TN) / (TP + TN + FP + FN), 4)\n",
    "\n",
    "    # Calculate AUC\n",
    "    if 'auc' in metrics and y_prob is not None:\n",
    "        # Note: AUC requires probabilities, not class labels.\n",
    "        results['auc'] = round( roc_auc_score(y_true, y_prob), 4)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_excel('cleaned data.xlsx')\n",
    "\n",
    "# Save as dataframe\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X (features) and y (response)\n",
    "X = data.drop(['Pno', 'Take-up ind'], axis = 1)\n",
    "y = data['Take-up ind']\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# all my variables as seen as floats rather than strings or integers\n",
    "X = X.astype(np.float32).values\n",
    "y = y.astype(np.float32).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the test set (10%)\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, stratify=y, random_state=7)\n",
    "\n",
    "# Now training (70%) and validation sets (20%)\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train_val, y_train_val, test_size=0.2222, stratify=y_train_val, random_state=7)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=7)\n",
    "x_train_smote, y_train_smote = smote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
